{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature-scaling\n",
    "\n",
    "Use the \"Run\" button to execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jovian --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Creating a new project \"kartikaye-madhok/feature-scaling\"\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/kartikaye-madhok/feature-scaling\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ai/kartikaye-madhok/feature-scaling'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute this to save new versions of the notebook\n",
    "jovian.commit(project=\"feature-scaling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Feature scaling is the process of normalising the range of features in a dataset.\n",
    "\n",
    "Real-world datasets often contain features that are varying in degrees of magnitude, range and units. Therefore, in order for machine learning models to interpret these features on the same scale, we have to perform feature scaling.\n",
    "\n",
    "In science, we all know the importance of comparing apples to apples and yet many people, especially beginners, have a tendency to overlook feature scaling as part of the preprocessing steps for machine learning. This has proven to cause models to make inaccurate predictions.\n",
    "\n",
    "In this notebook, we will discuss why feature scaling is important, the difference between normalisation and standardisation as well as how feature scaling affects model accuracy. More specifically, we will explore the applications of 3 different types of scalers in the Scikit-learn library:\n",
    "\n",
    "1. [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)\n",
    "2. [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "3. [RobustScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Wrangling\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data Visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import Dataset\n",
    "\n",
    "For the purpose of this notebook, we will use one of the toy datasets in Scikit-learn library, the [Boston house prices dataset.](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html)\n",
    "\n",
    "You can find the description of the features [here.](https://scikit-learn.org/stable/datasets/toy_dataset.html#boston-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston=load_boston()\n",
    "\n",
    "data=pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "data['target']=boston.target\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The abreviations of the attributes is as follows:\n",
    "\n",
    "1. CRIM per capita crime rate by town\n",
    "\n",
    "2. ZN proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "\n",
    "3. INDUS proportion of non-retail business acres per town\n",
    "\n",
    "4. CHAS Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "\n",
    "5. NOX nitric oxides concentration (parts per 10 million)\n",
    "\n",
    "6. RM average number of rooms per dwelling\n",
    "\n",
    "7. AGE proportion of owner-occupied units built prior to 1940\n",
    "\n",
    "8. DIS weighted distances to five Boston employment centres\n",
    "\n",
    "9. RAD index of accessibility to radial highways\n",
    "\n",
    "10. TAX full-value property-tax rate per $10,000\n",
    "\n",
    "11. PTRATIO pupil-teacher ratio by town\n",
    "\n",
    "12. B 1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n",
    "\n",
    "13. LSTAT % lower status of the population\n",
    "\n",
    "14. MEDV Median value of owner-occupied homes in $1000’s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    float64\n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  target   506 non-null    float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "# missing values and data type\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that there are no missing values, **which is great!!!**\n",
    "\n",
    "It also appears that our independent variables and our target variables are of the `float64` data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>506.0</td>\n",
       "      <td>3.613524</td>\n",
       "      <td>8.601545</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.25651</td>\n",
       "      <td>3.677083</td>\n",
       "      <td>88.9762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>506.0</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>506.0</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.46000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>9.69000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>27.7400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>506.0</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>506.0</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.38500</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>0.53800</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.8710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>506.0</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>3.56100</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>6.20850</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>8.7800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>506.0</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.90000</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>77.50000</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>506.0</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>1.12960</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>3.20745</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>12.1265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>506.0</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>506.0</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>187.00000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>330.00000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>711.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>506.0</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>12.60000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>19.05000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>22.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>506.0</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>0.32000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>391.44000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>396.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>506.0</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>1.73000</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>11.36000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>37.9700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>506.0</td>\n",
       "      <td>22.532806</td>\n",
       "      <td>9.197104</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>17.025000</td>\n",
       "      <td>21.20000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>50.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count        mean         std        min         25%        50%  \\\n",
       "CRIM     506.0    3.613524    8.601545    0.00632    0.082045    0.25651   \n",
       "ZN       506.0   11.363636   23.322453    0.00000    0.000000    0.00000   \n",
       "INDUS    506.0   11.136779    6.860353    0.46000    5.190000    9.69000   \n",
       "CHAS     506.0    0.069170    0.253994    0.00000    0.000000    0.00000   \n",
       "NOX      506.0    0.554695    0.115878    0.38500    0.449000    0.53800   \n",
       "RM       506.0    6.284634    0.702617    3.56100    5.885500    6.20850   \n",
       "AGE      506.0   68.574901   28.148861    2.90000   45.025000   77.50000   \n",
       "DIS      506.0    3.795043    2.105710    1.12960    2.100175    3.20745   \n",
       "RAD      506.0    9.549407    8.707259    1.00000    4.000000    5.00000   \n",
       "TAX      506.0  408.237154  168.537116  187.00000  279.000000  330.00000   \n",
       "PTRATIO  506.0   18.455534    2.164946   12.60000   17.400000   19.05000   \n",
       "B        506.0  356.674032   91.294864    0.32000  375.377500  391.44000   \n",
       "LSTAT    506.0   12.653063    7.141062    1.73000    6.950000   11.36000   \n",
       "target   506.0   22.532806    9.197104    5.00000   17.025000   21.20000   \n",
       "\n",
       "                75%       max  \n",
       "CRIM       3.677083   88.9762  \n",
       "ZN        12.500000  100.0000  \n",
       "INDUS     18.100000   27.7400  \n",
       "CHAS       0.000000    1.0000  \n",
       "NOX        0.624000    0.8710  \n",
       "RM         6.623500    8.7800  \n",
       "AGE       94.075000  100.0000  \n",
       "DIS        5.188425   12.1265  \n",
       "RAD       24.000000   24.0000  \n",
       "TAX      666.000000  711.0000  \n",
       "PTRATIO   20.200000   22.0000  \n",
       "B        396.225000  396.9000  \n",
       "LSTAT     16.955000   37.9700  \n",
       "target    25.000000   50.0000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary Statistics\n",
    "\n",
    "data.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that our features span across different range of values. This may be attributed to the different units in wwhich these features were measured and recorded.\n",
    "\n",
    "This is where feature scaling will help us solve this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 5. Understand the effects of Different Scalers\n",
    "\n",
    "In this section, we will learn the distinction between `normalisation` and `standardisation.` Subsequently, we will look at the effects of 3 different feature scaling techniques in Scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 5.1 Theory\n",
    "Before we examine the effects of feature scaling, let us first go over some theories behind normalisation and standardisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 5.1.1 Normalisation\n",
    "\n",
    "Normalisation, also known as min-max scaling, is a scaling technique whereby the values in a column are shifted so that they are bounded between a fixed range of 0 and 1.\n",
    "\n",
    "**X_new = (X - X_min) / (X_max - X_min)**\n",
    "\n",
    "[MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) is the Scikit-learn function for normalisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 5.1.2 Standardisation\n",
    "\n",
    "On the other hand, standardisation or Z-score normalisation is another scaling technique whereby the values in a column are rescaled so that they demonstrate the properties of a standard Gaussian distribution, that is mean = 0 and variance = 1.\n",
    "\n",
    "**X_new = (X - mean) / std**\n",
    "\n",
    "[StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) is the Scikit-learn function for standardisation.\n",
    "\n",
    "Unlike StandardScaler, [RobustScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html) scales features using statistics that are robust to outliers. More specifically, this scaler removes the median and scales the data according to the quantile range or by default, the interquartile range, thus making it less susceptible to outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Normalisation V Standardisation\n",
    "\n",
    "The choice between normalisation or standardisation comes down to the application.\n",
    "\n",
    "Standardisation is generally preferred over normalisation in most machine learning context as it is especially important in order to compare the similarities between features based on certain distance measures. This is most prominent in [Principal Component Analysis (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis) where we are interested in the components that maximise the variance.\n",
    "\n",
    "Normalisation, on the other hand, also offers many practical applications particularly in computer vision and image processing where pixel intensities have to be normalised to fit within a the RGB colour range between 0 and 255. Furthermore, neural network algorithms typically require data to be normalised to a 0-1 scale before model training.\n",
    "\n",
    "At the end of the day, there is no definitive answer as to whether you should normalise or standardise your data. One can always apply both techniques and compare the model performance for the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 5.2 Application\n",
    "\n",
    "Now that we have a theoretical understanding of feature scaling, let's see how they work in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (506, 13)\n",
      "Y shape:  (506,)\n"
     ]
    }
   ],
   "source": [
    "# Get predictor and target variables\n",
    "\n",
    "X = data.drop('target', axis = 1)\n",
    "Y = data['target']\n",
    "\n",
    "# X, Y shape\n",
    "\n",
    "print(\"X shape: \", X.shape)\n",
    "print(\"Y shape: \", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create Objects for MinMaxScaler, StandardScaler and RobustScaler\n",
    "\n",
    "norm=MinMaxScaler()\n",
    "standard=StandardScaler()\n",
    "robust=RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# MinMaxScaler\n",
    "normalised_features = norm.fit_transform(X)\n",
    "normalised_df = pd.DataFrame(normalised_features, index = X.index, columns = X.columns)\n",
    "\n",
    "# StandardScaler\n",
    "standardised_features = standard.fit_transform(X)\n",
    "standardised_df = pd.DataFrame(standardised_features, index = X.index, columns = X.columns)\n",
    "\n",
    "# RobustScaler\n",
    "robust_features = robust.fit_transform(X)\n",
    "robust_df = pd.DataFrame(robust_features, index = X.index, columns = X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To demonstrate the effects of different scalers, I have chosen to examine the following features in our dataset before and after implementing feature scaling:\n",
    "\n",
    "1. **ZN** [ZN proportion of residential land zoned for lots over 25,000 sq.ft.]\n",
    "2. **AGE** [AGE proportion of owner-occupied units built prior to 1940]\n",
    "3. **TAX** [TAX full-value property-tax rate per $10,000]\n",
    "4. **B** [B 1000(Bk - 0.63)^2 where Bk is the proportion of black people by town]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 5.2.2 Visualisations\n",
    "\n",
    "**NOTE** I came across a very intersting pandas function called [pd.melt](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.melt.html)\n",
    "--------------------------------------------------------------------------------------------------------------------------\n",
    "This function is useful to massage a DataFrame into a format where one or more columns are identifier variables (id_vars), while all other columns, considered measured variables (value_vars), are “unpivoted” to the row axis, leaving just two non-identifier columns, ‘variable’ and ‘value’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Subplots\n",
    "\n",
    "fig, ax = plt.subplots(2,2,figsize=(12,9))\n",
    "\n",
    "\n",
    "\n",
    "#Original\n",
    "\n",
    "sns.barplot(x='variable', y='value', data=pd.melt(data[['ZN','AGE','TAX','B']]), ax=ax[0,0])\n",
    "ax[0,0].set_title('Original')\n",
    "ax[0,0].set_xlabel('')\n",
    "ax[0,0].set_ylabel('')\n",
    "\n",
    "# MinMaxScaler\n",
    "\n",
    "sns.boxplot(x = 'variable', y = 'value', data = pd.melt(normalised_df[['ZN', 'AGE', 'TAX', 'B']]), ax = ax[0, 1])\n",
    "ax[0, 1].set_title('MinMaxScaler')\n",
    "ax[0, 1].set_xlabel('')\n",
    "ax[0, 1].set_ylabel('')\n",
    "\n",
    "#StandardScaler\n",
    "\n",
    "sns.boxplot(x = 'variable', y = 'value', data = pd.melt(standardised_df[['ZN', 'AGE', 'TAX', 'B']]), ax = ax[1, 0])\n",
    "ax[1, 0].set_title('StandardScaler')\n",
    "ax[1, 0].set_xlabel('')\n",
    "ax[1, 0].set_ylabel('')\n",
    "\n",
    "#RobustScaler\n",
    "\n",
    "sns.boxplot(x = 'variable', y = 'value', data = pd.melt(robust_df[['ZN', 'AGE', 'TAX', 'B']]), ax = ax[1, 1])\n",
    "ax[1, 1].set_title('RobustScaler')\n",
    "ax[1, 1].set_xlabel('')\n",
    "ax[1, 1].set_ylabel('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As we can see, our original features have wildly different ranges.\n",
    "\n",
    "MinMaxScaler has rescaled our features so that their values are bounded between 0 and 1.\n",
    "\n",
    "StandardScaler and RobustScaler, on the other hand, have rescaled our features so that they are distributed around the mean of 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Model Accuracy\n",
    "\n",
    "I mentioned in the introduction of this tutorial that unscaled data can adversely impact a model's ability to make accurate predictions but so far, we have not discussed exactly how and why they do. In fact, feature scaling does not always improve a model's performance. Some models do not require feature scaling.\n",
    "\n",
    "In this section, we will explore the following classes of machine learning algorithms and discuss whether or not feature scaling impact their performance:\n",
    "\n",
    "1. Gradient descent based algorithms\n",
    "2. Distance-based algorithms\n",
    "3. Tree-based algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Theory\n",
    "\n",
    "Let's first go over some concepts behind those algorithms and think about how and why feature scaling might be important to each of them.\n",
    "\n",
    "Cheatsheet.\n",
    "---\n",
    "![](https://i.imgur.com/aOZsaWa.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 6.1.1 Gradient Descent Based Algorithms\n",
    "\n",
    "Gradient desent is an iterative optimisation algorithm that takes us to the minimum of a function. Machine learning algorithms like `linear regression` and `logistic regression` rely on gradient descent to minimise their loss functions or in other words, to reduce the error between the predicted values and the actual values.\n",
    "\n",
    "Having features with varying range of values will cause different step sizes for each feature. Therefore, to ensure that gradient descent converges more smoothly and quickly, we need to scale our features so that they have a similar scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 6.1.2 Distance Based Algorithms\n",
    "\n",
    "The underlying algorithms to distance-based models make them the most susceptible to unscaled data.\n",
    "\n",
    "Algorithms like `k-nearest neighbours`, `support vector machines` and `k-means clustering` use the distance between data points to determine their similarity. Hence, features with a greater magnitude will be given a higher weightage by the model. This is not an ideal scenario as we do not want our algorithm to be heavily biased towards a single feature.\n",
    "\n",
    "Evidently, it is important that we implement feature scaling to our data before fitting them to distance-based algorithms to ensure that all features contribute equally to the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 6.1.3 Tree Based Algorithms\n",
    "\n",
    "Each node in a `Classification And Regression Trees (CART)` model, otherwise known as `Decision Trees` represents a single feature in a dataset. The tree splits each node in such a way that it increases the homogeneity of that node. This split is not affected by the other features in the dataset.\n",
    "\n",
    "For that reason, we can conclude that decision trees are invariant to the scale of the features and therefore do not require feature scaling. This includes other ensemble models that are also tree-based such as random forest and gradient boosting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Proof Of Concept\n",
    "\n",
    "Now that we understand the types of models that are sensitive and insensitive to feature scaling, let us now convince ourselves with a concrete example using the Boston house prices dataset.\n",
    "\n",
    "Here, I have chosen 2 distance-based algorithms (`KNN` and `SVR`) as well as 1 tree-based algorithm (`decision trees regressor`) to predict the house prices.\n",
    "\n",
    "We should expect to see an improved model performance with feature scaling under KNN and SVR and a constant model performance under decision trees with and without feature scaling.\n",
    "\n",
    "Feel free to experiment with other types of models like linear regression, random forest and gradient boosting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Objects\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "svr = SVR()\n",
    "tree = DecisionTreeRegressor(max_depth=10, random_state=42)\n",
    "\n",
    "#Create list of Different Scalers\n",
    "\n",
    "scalers = [norm, standard, robust]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (379, 13)\n",
      "Y_train shape:  (379,)\n",
      "X_test shape:  (127, 13)\n",
      "Y_test shape:  (127,)\n"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 42)\n",
    "\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"Y_train shape: \", Y_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"Y_test shape: \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started, I think it is important to highlight the good practice of first fitting the scalers to the training set and then use that to transform the data in the test set. This is to prevent any data leakage and misleading accuracy scores.\n",
    "\n",
    "Here, I will construct a pipeline which contains a scaler and a model to fit and transform the features and subsequently make predictions using each model. The accuracy of these predictions are then evaluated using root mean squared error. The smaller the error, the better the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.1 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Original</th>\n",
       "      <td>5.023266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MinMaxScaler</th>\n",
       "      <td>4.534415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StandardScaler</th>\n",
       "      <td>4.487861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RobustScaler</th>\n",
       "      <td>4.404341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    RMSE\n",
       "Original        5.023266\n",
       "MinMaxScaler    4.534415\n",
       "StandardScaler  4.487861\n",
       "RobustScaler    4.404341"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_rmse = []\n",
    "\n",
    "# Without feature scaling\n",
    "\n",
    "knn.fit(X_train, Y_train)\n",
    "pred = knn.predict(X_test)\n",
    "knn_rmse.append(np.sqrt(mean_squared_error(Y_test, pred)))\n",
    "\n",
    "# Apply different scaling techniques and make predictions using KNN \n",
    "\n",
    "for scaler in scalers:\n",
    "    pipe = make_pipeline(scaler, knn)\n",
    "    pipe.fit(X_train, Y_train)\n",
    "    pred = pipe.predict(X_test)\n",
    "    knn_rmse.append(np.sqrt(mean_squared_error(Y_test, pred)))\n",
    "\n",
    "# Show results     \n",
    "\n",
    "knn_df = pd.DataFrame({'RMSE': knn_rmse}, index = ['Original', 'MinMaxScaler', 'StandardScaler', 'RobustScaler'])\n",
    "knn_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the errors are much smaller with feature scaling than without feature scaling. In other words, our model performed better using scaled features.\n",
    "\n",
    "In this instance, KNN performed best under `RobustScaler.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.2 SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Original</th>\n",
       "      <td>7.020270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MinMaxScaler</th>\n",
       "      <td>5.127946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StandardScaler</th>\n",
       "      <td>5.033967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RobustScaler</th>\n",
       "      <td>5.323447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    RMSE\n",
       "Original        7.020270\n",
       "MinMaxScaler    5.127946\n",
       "StandardScaler  5.033967\n",
       "RobustScaler    5.323447"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_rmse = []\n",
    "\n",
    "# Without feature scaling\n",
    "\n",
    "svr.fit(X_train, Y_train)\n",
    "pred = svr.predict(X_test)\n",
    "svr_rmse.append(np.sqrt(mean_squared_error(Y_test, pred)))\n",
    "\n",
    "# Apply different scaling techniques and make predictions using SVR\n",
    "\n",
    "for scaler in scalers:\n",
    "    pipe = make_pipeline(scaler, svr)\n",
    "    pipe.fit(X_train, Y_train)\n",
    "    pred = pipe.predict(X_test)\n",
    "    svr_rmse.append(np.sqrt(mean_squared_error(Y_test, pred)))\n",
    "\n",
    "# Show results\n",
    "\n",
    "svr_df = pd.DataFrame({'RMSE': svr_rmse}, index = ['Original', 'MinMaxScaler', 'StandardScaler', 'RobustScaler'])\n",
    "svr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to KNN, SVR also performed better with scaled features as seen by the lower errors.\n",
    "\n",
    "In this instance, SVR performed best under StandardScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.3 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Original</th>\n",
       "      <td>3.306176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MinMaxScaler</th>\n",
       "      <td>3.306176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StandardScaler</th>\n",
       "      <td>3.306176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RobustScaler</th>\n",
       "      <td>3.306176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    RMSE\n",
       "Original        3.306176\n",
       "MinMaxScaler    3.306176\n",
       "StandardScaler  3.306176\n",
       "RobustScaler    3.306176"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_rmse = []\n",
    "\n",
    "# Without feature scaling\n",
    "\n",
    "tree.fit(X_train, Y_train)\n",
    "pred = tree.predict(X_test)\n",
    "tree_rmse.append(np.sqrt(mean_squared_error(Y_test, pred)))\n",
    "\n",
    "# Apply different scaling techniques and make predictions using decision tree\n",
    "\n",
    "for scaler in scalers:\n",
    "    pipe = make_pipeline(scaler, tree)\n",
    "    pipe.fit(X_train, Y_train)\n",
    "    pred = pipe.predict(X_test)\n",
    "    tree_rmse.append(np.sqrt(mean_squared_error(Y_test, pred)))\n",
    "\n",
    "# Show results \n",
    "\n",
    "tree_df = pd.DataFrame({'RMSE': tree_rmse}, index = ['Original', 'MinMaxScaler', 'StandardScaler', 'RobustScaler'])\n",
    "tree_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, decision tree is insensitive to all feature scaling techniques as seen in the constant RMSE across scaled and unscaled features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "To summarise, feature scaling is the process of transforming the features in a dataset so that their values share a similar scale.\n",
    "\n",
    "In this notebook, we have learned the difference between normalisation and standardisation as well as 3 different scalers in the Scikit-learn library: MinMaxScaler, StandardScaler and RobustScaler.\n",
    "\n",
    "We also learned that gradient descent and distance-based algorithms require feature scaling while tree-based algorithms do not. We managed to prove this via an example with the Boston house prices dataset and comparing the model accuracy with and without feature scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. References\n",
    "\n",
    "1. [Feature Scaling for Machine Learning: Understanding the Difference Between Normalization vs. Standardization](https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/)\n",
    "\n",
    "2. [Normalization vs Standardization](https://www.geeksforgeeks.org/normalization-vs-standardization/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Follow me on other platforms\n",
    "\n",
    "1. [Linkedln](https://www.linkedin.com/in/kartikaye-madhok-80a50298/)\n",
    "2. [Github](https://github.com/AceVentura7)\n",
    "3. [Medium](https://medium.com/@kartikaye.madhok)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}